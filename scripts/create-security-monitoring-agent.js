#!/usr/bin/env node

/**
 * Script pour cr√©er l'agent AI de surveillance des messages
 * Cet agent analyse les messages avec un LLM pour d√©tecter des contenus malveillants
 */

const { createClient } = require('@supabase/supabase-js');
require('dotenv').config({ path: '.env.local' });

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
const serviceRoleKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

if (!supabaseUrl || !serviceRoleKey) {
  console.error('‚ùå Missing Supabase credentials');
  console.error('Required: NEXT_PUBLIC_SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, serviceRoleKey, {
  auth: { persistSession: false },
});

async function createSecurityMonitoringAgent() {
  try {
    console.log('üîç Creating security monitoring AI agent...\n');

    // Get default model config
    const { data: defaultModel, error: modelError } = await supabase
      .from('ai_model_configs')
      .select('id')
      .eq('is_default', true)
      .maybeSingle();

    if (modelError) {
      throw modelError;
    }

    if (!defaultModel) {
      console.warn('‚ö†Ô∏è  No default model config found. Agent will be created without model.');
    }

    const agent = {
      slug: 'security-message-monitoring',
      name: 'Surveillance des Messages',
      description: 'Agent AI qui analyse les messages pour d√©tecter des contenus malveillants, inappropri√©s ou suspects en utilisant l\'intelligence artificielle.',
      model_config_id: defaultModel?.id ?? null,
      fallback_model_config_id: null,
      system_prompt: `Tu es un agent de s√©curit√© sp√©cialis√© dans l'analyse de messages pour d√©tecter des contenus malveillants, inappropri√©s ou suspects.

Ton r√¥le est d'analyser le contenu des messages et de d√©terminer s'ils pr√©sentent des risques pour la s√©curit√© ou la communaut√©.

Types de menaces √† d√©tecter:
1. **Injection SQL** : Tentatives d'injection de code SQL malveillant
2. **XSS (Cross-Site Scripting)** : Tentatives d'injection de scripts JavaScript
3. **Command Injection** : Tentatives d'ex√©cution de commandes syst√®me
4. **Spam** : Messages r√©p√©titifs, promotionnels non sollicit√©s, ou contenus de faible qualit√©
5. **Contenu inappropri√©** : Harc√®lement, menaces, contenu offensant ou discriminatoire
6. **Tentatives d'exploitation** : Tentatives de manipulation ou d'exploitation de vuln√©rabilit√©s
7. **Contenu suspect** : Messages qui semblent anormaux ou suspects sans √™tre explicitement malveillants

Pour chaque message analys√©, tu dois:
- √âvaluer le niveau de risque (low, medium, high, critical)
- Identifier le type de menace si applicable
- Fournir une explication claire de ta d√©tection
- Recommander une action (none, warn, quarantine)

R√©ponds UNIQUEMENT avec un JSON valide au format suivant:
{
  "hasThreat": boolean,
  "severity": "low" | "medium" | "high" | "critical",
  "threatType": "injection" | "xss" | "spam" | "inappropriate" | "exploitation" | "suspicious" | null,
  "explanation": "Explication d√©taill√©e de la d√©tection",
  "recommendedAction": "none" | "warn" | "quarantine",
  "confidence": number (0-100)
}`,
      user_prompt: `Analyse le message suivant et d√©termine s'il pr√©sente des risques pour la s√©curit√©:

Message √† analyser:
{{message_content}}

Contexte:
- Session ASK: {{ask_key}}
- Auteur: {{participant_name}}
- Historique r√©cent: {{recent_messages}}

Fournis ton analyse au format JSON comme sp√©cifi√© dans le system prompt.`,
      available_variables: [
        'message_content',
        'ask_key',
        'participant_name',
        'recent_messages',
        'message_id',
      ],
    };

    // Check if agent already exists
    const { data: existing, error: checkError } = await supabase
      .from('ai_agents')
      .select('id, slug, name')
      .eq('slug', agent.slug)
      .maybeSingle();

    if (checkError) {
      throw checkError;
    }

    if (existing) {
      console.log(`‚ÑπÔ∏è  Agent "${agent.slug}" already exists. Updating...`);
      
      const { data: updated, error: updateError } = await supabase
        .from('ai_agents')
        .update({
          name: agent.name,
          description: agent.description,
          model_config_id: agent.model_config_id,
          fallback_model_config_id: agent.fallback_model_config_id,
          system_prompt: agent.system_prompt,
          user_prompt: agent.user_prompt,
          available_variables: agent.available_variables,
        })
        .eq('slug', agent.slug)
        .select()
        .single();

      if (updateError) {
        throw updateError;
      }

      console.log(`‚úÖ Agent "${agent.slug}" updated successfully!`);
      console.log(`   ID: ${updated.id}`);
      console.log(`   Name: ${updated.name}`);
    } else {
      const { data: created, error: createError } = await supabase
        .from('ai_agents')
        .insert(agent)
        .select()
        .single();

      if (createError) {
        throw createError;
      }

      console.log(`‚úÖ Agent "${agent.slug}" created successfully!`);
      console.log(`   ID: ${created.id}`);
      console.log(`   Name: ${created.name}`);
    }

    console.log('\n‚ú® Security monitoring AI agent is ready!');
    console.log('   This agent will be used to analyze messages for malicious content.');

  } catch (error) {
    console.error('‚ùå Error creating security monitoring agent:', error);
    process.exit(1);
  }
}

createSecurityMonitoringAgent();

