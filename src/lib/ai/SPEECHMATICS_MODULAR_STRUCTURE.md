# Structure Modulaire pour Speechmatics Voice Agent

## üìÅ Fichiers Cr√©√©s

Le fichier `speechmatics.ts` (1486 lignes) a √©t√© divis√© en modules plus petits et maintenables :

### 1. `speechmatics-types.ts`
- **Contenu** : Tous les types, interfaces et callbacks
- **Exports** :
  - `SpeechmaticsConfig`
  - `SpeechmaticsMessageEvent`
  - `SpeechmaticsMessageCallback`
  - `SpeechmaticsErrorCallback`
  - `SpeechmaticsConnectionCallback`
  - `SpeechmaticsAudioCallback`

### 2. `speechmatics-auth.ts`
- **Contenu** : Gestion de l'authentification
- **Classe** : `SpeechmaticsAuth`
- **M√©thodes** :
  - `authenticate()` - Authentification Speechmatics (JWT ou API key)
  - `getElevenLabsApiKey()` - R√©cup√©ration de la cl√© ElevenLabs
  - `getJWT()` / `getApiKey()` - Getters pour les tokens
  - `hasJWT()` - V√©rification de validit√© du JWT

### 3. `speechmatics-audio-dedupe.ts`
- **Contenu** : Syst√®me de d√©duplication des chunks audio
- **Classe** : `AudioChunkDedupe`
- **M√©thodes** :
  - `computeChunkSignature(chunk)` - Calcul de la signature d'un chunk
  - `shouldSkipChunk(signature)` - V√©rification si un chunk est un doublon
  - `reset()` - R√©initialisation du cache

### 4. `speechmatics-transcription.ts`
- **Contenu** : Gestion des transcriptions (partielles et finales)
- **Classe** : `TranscriptionManager`
- **M√©thodes** :
  - `handlePartialTranscript(transcript)` - Traitement des transcriptions partielles
  - `handleFinalTranscript(transcript)` - Traitement des transcriptions finales
  - `processPendingTranscript()` - Traitement apr√®s d√©tection de silence
  - `resetSilenceTimeout()` - Gestion du timeout de silence
  - `cleanup()` - Nettoyage

### 5. `speechmatics-llm.ts`
- **Contenu** : Int√©gration LLM
- **Classe** : `SpeechmaticsLLM`
- **M√©thodes** :
  - `getLLMApiKey(provider)` - R√©cup√©ration de la cl√© API LLM
  - `callLLM(provider, apiKey, model, messages)` - Appel au LLM

## üîÑ Prochaines √âtapes (Optionnel)

Pour compl√©ter la modularisation, on pourrait cr√©er :

### 6. `speechmatics-websocket.ts`
- Gestion de la connexion WebSocket
- Gestion des messages WebSocket
- Configuration de la connexion

### 7. `speechmatics-audio.ts`
- Gestion du microphone (start/stop)
- Gestion du playback audio (TTS)
- Voice Activity Detection (VAD)
- Barge-in handling

### 8. `speechmatics.ts` (Refactoris√©)
- Classe principale qui orchestre tous les modules
- Utilise les classes modulaires cr√©√©es
- Beaucoup plus court et lisible

## üí° Avantages de cette Structure

1. **S√©paration des responsabilit√©s** : Chaque module a un r√¥le clair
2. **Maintenabilit√©** : Plus facile de trouver et modifier du code
3. **Testabilit√©** : Chaque module peut √™tre test√© ind√©pendamment
4. **R√©utilisabilit√©** : Les modules peuvent √™tre r√©utilis√©s ailleurs
5. **Lisibilit√©** : Le fichier principal sera beaucoup plus court

## üìù Exemple d'Utilisation (Apr√®s Refactoring)

```typescript
import { SpeechmaticsVoiceAgent } from './speechmatics';
import { SpeechmaticsAuth } from './speechmatics-auth';
import { AudioChunkDedupe } from './speechmatics-audio-dedupe';
import { TranscriptionManager } from './speechmatics-transcription';
import { SpeechmaticsLLM } from './speechmatics-llm';

// Dans la classe principale :
private auth = new SpeechmaticsAuth();
private audioDedupe = new AudioChunkDedupe();
private transcriptionManager: TranscriptionManager;
private llm = new SpeechmaticsLLM();
```

## ‚ö†Ô∏è Note

Les modules sont cr√©√©s mais le fichier principal `speechmatics.ts` n'a pas encore √©t√© refactoris√© pour les utiliser. Le code actuel continue de fonctionner comme avant.

Pour refactoriser compl√®tement, il faudrait :
1. Cr√©er les modules manquants (WebSocket, Audio)
2. Refactoriser `speechmatics.ts` pour utiliser tous les modules
3. Tester que tout fonctionne correctement

Souhaitez-vous que je continue avec le refactoring complet ?

## üéØ D√©tection S√©mantique de Fin de Tour

Le pipeline Speechmatics inclut d√©sormais un d√©tecteur d'arr√™t s√©mantique optionnel.

- **Helper d√©di√©** : `src/lib/ai/turn-detection.ts` formate les derniers tours en ChatML, appelle un SLM l√©ger (HTTP/OpenAI compatible) et calcule la probabilit√© combin√©e des tokens `<|im_end|>` / ponctuation forte.
- **Configuration** : tir√©e directement de la configuration mod√®le enregistr√©e en base (`ai_model_configs`). Par d√©faut on cible le slug `mistral-small` (provider **Mistral**, base URL `https://api.mistral.ai/v1`, variable API `MISTRAL_API_KEY`). Les autres param√®tres (`SEMANTIC_TURN_PROB_THRESHOLD`, `SEMANTIC_TURN_GRACE_MS`, `SEMANTIC_TURN_MAX_HOLD_MS`, `SEMANTIC_TURN_FALLBACK`) restent ajustables via `turn-detection-config.ts`.
- **Int√©gration pipeline** :
  - `TranscriptionManager` d√©clenche la requ√™te s√©mantique lors d'un silence VAD ou du signal Speechmatics `EndOfUtterance`.
  - Si la probabilit√© est inf√©rieure au seuil, un d√©lai configurable (grace period) maintient l'√©coute avant de relancer une requ√™te.
  - Quand la probabilit√© d√©passe le seuil, la finalisation est forc√©e et la r√©ponse agent est d√©clench√©e imm√©diatement.
- **UI & t√©l√©m√©trie** :
  - `SpeechmaticsVoiceAgent` propage les √©v√©nements (`hold`, `dispatch`, `fallback`) via un callback `onSemanticTurn`.
  - `PremiumVoiceInterface` affiche l'√©tat courant (hold/dispatch/fallback) sous l'indicateur de statut vocal.

Des tests unitaires couvrent le helper SLM et un sc√©nario bout-en-bout VAD+d√©tection pour s√©curiser la logique.



